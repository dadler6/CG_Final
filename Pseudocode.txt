Idea for the algorithm...based on paper.

I. Initialization  (fd)
	a. function that randomly partitions reads into contigs.
	b. function that for each contig, randomly places each read to a particular position in the contig from 0 to n-k+1. 
	c. initalize alpha contig lists of length N. (N = 10 kb?) 
	d. call consensus sequence function to initialize contig sequence.	

		- incorporate prior on s when initializing reads to contigs (i.e. more reads should go to contigs 1,2,3 and less on the rest). 

II. Consensus Sequence Step (dan)
	a. simple max consensus nucleotide function


III. Read Mapping (farhan)
	i. p(s, o, y | .) 

	ii. functions
		a. p(o) - uniform. 
		b. p(s) - geometric distribution
		c. p(x,y) - noise model
		d. y* -> hamming distance function
		e. sampling
	iii. computing p(s,o | y*, . ) using approximate inference
		a. metropolis hastings function

IV. Merge (dan)
	a. merge check function (looks at overlaps at ends of contigs to determine if merge is necessary. use 15 k-mer overlap)
	b. Also completes merge as necessary

v. Likelihood (farhan)
	a. compute likelihood.

algorithm on a high level:
	initialize
	while (delta likelihood > .1)
		read mapping
		consensus sequence
		check if you need to merge
		check likelihood.  


===================================================

Pseudocode

def _process():
	store reads in a list
	randomly partition reads into 7 clusters where each cluster corresponds to the reads that make a contig (each cluster is a list)
	for each contig
		randomly partition reads to a position from 0 to n-k+1 (we will use a dictionary mapping reads to position)
	append reads_to_positions_dictionary to list where each index corresponds to dictionary for a specific contig
	return list

def _consensus_sequence(reads_to_positions_dictionary):	
	return updated_contig_sequence


def _read_mapping():
	return list # same structure as what process returns

# ---------------------------------
# helper functions for read_mapping
def _compute_p_o():
	return p

def _compute_p_s():
	return p

def _compute_p_x_y():
	return p

def _compute_p_o_s_y():
	return p

def _compute_y_star():
	return y_star, s, o # optimal sequence alignment of x to a contig, contig num, offset in contig 

def _compute_hamming_distance(sequence_one, sequence_two):
	return dist

def _metropolis_hastings():
	return boolean

# ---------------------------------

def _merge_contigs(contigs_list, check_dictionary):
	# The check dictionary is formatted as [[contig1,contig2]: True/False] (true if contig1/contig2 should be
	  merged, otherwise false
	return list_updated_contigs

def _merge_check_global(contigs_list):
	# call this function in main. this function will check if any two contigs need to be merged. 
	# if two contigs need to be merged, it will call _merge_contigs.
	# if no contigs need to be merged, it will do nothing.
	return new_contigs_list

def _merge_check_local(contig_one, contig_two):
	return boolean (actually going to do 0,1) (If true, merge suffix of contig_one to prefix of contig_two)


def _likelihood():
	return likelihood


def _main():
	list = _process()
	contigs_list = []
	for l in list: contigs_list.append(_consensus_sequence(l)) # append updated contig sequences to list
	likelihood = 0
	while (delta likelihood > 1):
		call read mapping function
		call update_consensus_sequence			
		call _merge_check_global
		likelihood = _likelihood()


